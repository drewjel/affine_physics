## Overview

This directory stores all of our evaluation code for Peirce.
This document describes the structure of test cases, 

## Structure

Each evaluation test case is stored in its own folder, identified by a natural number and a short string description.

The directory structure is as follows:

/{NumberIdentifier}-{Short String Description}/
    /project/{Github Repository}
    /error_src/
        file1.[h|cpp]
        ...
        filen.[h|cpp]
    /test_case/
        test_annotation1
        ...
        test_annotationn
        test_cmd1
        ...
        test_cmdn
        test_file1.[cpp]
        ...
        test_filen.cpp[cpp]
        test_output1
        ...
        test_outputn
    short_description.md
    detailed_description.md

## Description

Starting from the top down, each project has the original repository cloned into the /project 
folder. The project is set to the immediately prior commit to the seminal commit in which the issue we are error we hope to portray in Peirce is still present. 

Next, the relevant source files from the original repository that are specifically required to demonstrate the error are in /error_src. 

These are whittled down into test cases contained in /test_case/. Each test case contains a "cmd", an "annotation", an "input", and an "output" file. The cmd file contains both a command to run Peirce on the test case and allow the user to fill in annotations, as well as to run Peirce on test case and generate an output automatically. The annotation file is intended to be generated by Peirce upon successful annotation of the test case, in order to "replay" the test case without manual annotation. The test case file contains both the entirety of the relevant code snippet from the original project as a comment, embedded into a simple ROS program which runs a reduced version of the original code designed to demonstrate the error in the original. The output file (as of 2/21, a blank file) is intended to show the expected output of Peirce when ran on the file.

There may potentially be multiple test cases, which reflect my uncertainty on what code snippet is most appropriate as a test case. Also, certain projects may have multiple, separated snippets that to be broken into separate test cases.

Finally, each project has a "short_description.md" and "detailed_description.md", which contain brief vs short paragraph notes on all relevant aspects of the test case, such as an issue link, commit hash, a portion of the erroneous code, a description of the error, a categorization, possibly the location of where an error occurs (where it's applicable or possible to find the error), and a description of changes required in Peirce.


## How to run test cases

    For each test case, you'll want to navigate to the test_suite folder. You will want to run peirce on either "test_file1.cpp"
    or "test_file.cpp". Completed test cases are included in .vscode/launch.json. Uncomment out the test case that you want to run and press f5. OR, go to the test file in question and use the plugin on it.

